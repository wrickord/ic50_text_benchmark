{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3c1096-7a98-4d43-b7ee-37b000dd267e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b80014-2a9f-4f1c-a1c6-132c9f61b822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import math\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import lmdeploy\n",
    "from lmdeploy import GenerationConfig\n",
    "\n",
    "# Local imports\n",
    "\n",
    "# CUDA\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2938cd8b-7852-4423-867a-627a92c6eacf",
   "metadata": {},
   "source": [
    "# Llama-3.1-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba400323-1388-4318-9a6a-ac4c52eafe5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea838a89c2847f69e426fa4a856d591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] gemm_config.in is not found; using default GEMM algo\n"
     ]
    }
   ],
   "source": [
    "# Get model\n",
    "pipe = lmdeploy.pipeline('meta-llama/Meta-Llama-3.1-8B-Instruct')\n",
    "gen_config = GenerationConfig(temperature=0, max_new_tokens=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2060fe-c169-4614-a9d0-eafd6cc98518",
   "metadata": {},
   "outputs": [],
   "source": [
    "doi = '10.1016/j.bmcl.2010.08.086'\n",
    "txt_path = f'/data/rbg/users/vincentf/data_uncertainty/c340_txt/{doi.replace(\"/\", \"_\")}.txt'\n",
    "with open(txt_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Few-shot prompt with examples of input-output format\n",
    "response = pipe([\n",
    "    f'''\n",
    "    You are a researcher with a PhD from MIT EECS. Your training is in deep learning, computational biology, and text mining.\n",
    "    \n",
    "    You are tasked with summarizing data from the literature provided. The text will contain information about an IC50 assay \n",
    "    for a target: digestive enzyme Cytochrome P450 3A4 (CYP3A4), and we only care about CYP3A4 data, not other variants. \n",
    "\n",
    "    Your task is to summarize key experimental details like assay type, inhibitors, and the conditions.\n",
    "    \n",
    "    The output should only include details present in the text; do not infer or add anything. \n",
    "\n",
    "    INPUT:\n",
    "    {text}\n",
    "    \n",
    "    OUTPUT:\n",
    "    '''\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d37ec80-98f3-4976-8564-08bf96026d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc69f16-8ab4-4056-a8a1-b7fdbeb16dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99357795-8b80-4cb0-87ac-f066c9c77fd3",
   "metadata": {},
   "source": [
    "# MedLlama3-v20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37614601-7e8d-4a77-a076-6b826c29e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [\n",
    "#     {\"role\": \"user\", \"content\": \"computational biologist at MIT\"},\n",
    "# ]\n",
    "# pipe = pipeline(\"text-generation\", model=\"ProbeMedicalYonseiMAILab/medllama3-v20\")\n",
    "# pipe(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
