{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09c606d4-dce0-442c-8433-c431e30203ec",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b46add-7206-4e9d-9bbc-69cbc1901892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "# Local imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b5b16-1716-419a-9b31-81cd68e948a3",
   "metadata": {},
   "source": [
    "# Look at ChemBL Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9dcc438-e603-4c13-a544-a200f541c347",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File /data/rbg/users/vincentf/wrickord/code_repository/ic50_text_benchmark/_old_/data/chembl340_all_activities_annotated.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m json_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcur_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data/chembl340_all_activities_annotated.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load into DataFrame\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m chembl_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Investigate targets\u001b[39;00m\n\u001b[1;32m      9\u001b[0m unique_targets \u001b[38;5;241m=\u001b[39m chembl_df\u001b[38;5;241m.\u001b[39mtarget\u001b[38;5;241m.\u001b[39munique()\n",
      "File \u001b[0;32m/data/rbg/users/vincentf/wrickord/miniconda3/envs/ic50/lib/python3.11/site-packages/pandas/io/json/_json.py:791\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    789\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "File \u001b[0;32m/data/rbg/users/vincentf/wrickord/miniconda3/envs/ic50/lib/python3.11/site-packages/pandas/io/json/_json.py:904\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m filepath_or_buffer\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data_from_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[0;32m/data/rbg/users/vincentf/wrickord/miniconda3/envs/ic50/lib/python3.11/site-packages/pandas/io/json/_json.py:960\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    952\u001b[0m     filepath_or_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[1;32m    959\u001b[0m ):\n\u001b[0;32m--> 960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_or_buffer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal json to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_json\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    967\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    968\u001b[0m     )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File /data/rbg/users/vincentf/wrickord/code_repository/ic50_text_benchmark/_old_/data/chembl340_all_activities_annotated.json does not exist"
     ]
    }
   ],
   "source": [
    "# Get json file path\n",
    "cur_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "json_path = f'{cur_dir}/data/chembl340_all_activities_annotated.json'\n",
    "\n",
    "# Load into DataFrame\n",
    "chembl_df = pd.read_json(json_path)\n",
    "\n",
    "# Investigate targets\n",
    "unique_targets = chembl_df.target.unique()\n",
    "print(\n",
    "    f'Number of unique targets: {len(unique_targets)}',\n",
    "    f'\\nNumber of total rows: {len(chembl_df)}'\n",
    ")\n",
    "\n",
    "# We see only one target\n",
    "print(f'\\nTarget: {unique_targets[0]}')\n",
    "\n",
    "# Investigate number of entries with a document listed\n",
    "chembl_with_doc_df = chembl_df[\n",
    "    (chembl_df.document.notnull()) &\n",
    "    (chembl_df.target == unique_targets[0])\n",
    "].reset_index(drop=True)\n",
    "chembl_with_doc_df['original_index'] = np.arange(len(chembl_with_doc_df))\n",
    "print(f'\\nNumber of entries with a document attached: {len(chembl_with_doc_df)}')\n",
    "chembl_with_doc_df.to_json(f'{cur_dir}/data/chembl_CYP3A4_with_doi.json', orient='records')\n",
    "\n",
    "# Look at the supporting documents\n",
    "docs = chembl_with_doc_df.document\n",
    "docs_df = pd.json_normalize(docs)\n",
    "print(f'Information provided by document: {docs_df.columns.tolist()}')\n",
    "\n",
    "# Journal information (suggesting similar criteria for acceptance)\n",
    "journals = docs_df.journal.dropna().unique()\n",
    "print(f'\\nNumber of journals within supporting documents: {len(journals)}')\n",
    "print(f'Journal names: {journals}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7852c55-1678-4c9d-8db0-5763bb86bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract activities and preserve original indices\n",
    "activities = chembl_with_doc_df.activities.to_numpy().ravel().tolist()\n",
    "\n",
    "# Flatten the list of activities while preserving indices\n",
    "flattened_activities, original_indices, activity_indices = [], [], []\n",
    "for index, sublist in enumerate(activities):\n",
    "    for activity_index, item in enumerate(sublist):\n",
    "        flattened_activities.append(item)\n",
    "        original_indices.append(index)\n",
    "        activity_indices.append(activity_index)\n",
    "        \n",
    "activities_df = pd.DataFrame(flattened_activities)\n",
    "activities_df['original_index'] = original_indices\n",
    "activities_df['activity_index'] = activity_indices\n",
    "\n",
    "# Get the molecular weight from a smiles string\n",
    "def calculate_mol_weight(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    return Descriptors.ExactMolWt(mol)\n",
    "\n",
    "# Known unit conversion factors\n",
    "unit_dict = {\n",
    "    'mM': 1e3,\n",
    "    'nM': 1e-3\n",
    "}\n",
    "\n",
    "# Function to get unit conversion factor\n",
    "def get_conversion_factor(unit, mol_weight=None):\n",
    "    if unit == 'ug ml-1':\n",
    "        return 1e3 / mol_weight\n",
    "    elif unit == 'mg/ml':\n",
    "        return 1e6 / mol_weight\n",
    "    else:\n",
    "        return unit_dict.get(unit)\n",
    "\n",
    "# Units to convert to\n",
    "desired_units = ['uM', '10^-6 mol/L', 'microM', 'umol/L']\n",
    "\n",
    "# Function to convert units\n",
    "def convert_units(row):\n",
    "    smiles, value, unit = row['smiles'], row['value'], row['unit']\n",
    "    \n",
    "    if unit in desired_units:\n",
    "        row['unit'] = desired_units[0]\n",
    "        return row\n",
    "    \n",
    "    mol_weight = calculate_mol_weight(smiles)\n",
    "    conversion_factor = get_conversion_factor(unit, mol_weight)\n",
    "    if conversion_factor:\n",
    "        row['value'] = value * conversion_factor\n",
    "        row['unit'] = desired_units[0]\n",
    "    \n",
    "    return row\n",
    "\n",
    "# Fix activities data\n",
    "activities_df.columns = [\n",
    "    'molregno', 'relation', 'value', 'unit', \n",
    "    'standard_type', 'compound_name', 'smiles',\n",
    "    'original_index', 'activity_index'\n",
    "]\n",
    "\n",
    "# Allowed unit types\n",
    "allowed_units = [\n",
    "    'uM', '10^-6 mol/L', 'microM', 'umol/L', \n",
    "    'nM', 'mM', 'ug ml-1', # 'mg/ml'\n",
    "]\n",
    "\n",
    "# Remove incomplete rows\n",
    "activities_df = activities_df[\n",
    "    (activities_df['value'].notna()) &\n",
    "    (activities_df['value'] != 0) &\n",
    "    (activities_df['unit'].notna()) &\n",
    "    (activities_df['unit'].isin(allowed_units)) &\n",
    "    (activities_df['relation'].notna()) &\n",
    "    (activities_df['relation'] == '=')\n",
    "]\n",
    "\n",
    "# Convert ic50 value to correct units\n",
    "activities_df = activities_df.apply(convert_units, axis=1)\n",
    "\n",
    "print(f'Total number of activities for target: {len(activities_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2da6d-dadf-43e6-b803-fe7909d29351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine data into an overall dataframe\n",
    "combined_df = pd.concat([\n",
    "    chembl_with_doc_df.drop(columns=['document', 'activities']), \n",
    "    docs_df\n",
    "], axis=1).reset_index(drop=True)\n",
    "combined_df = pd.merge(activities_df, combined_df, how='left', left_on='original_index', right_on='original_index')\n",
    "\n",
    "print(f'Columns: {combined_df.columns.tolist()}\\n')\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3468c54c-db5f-469c-b11a-e4f0444e40de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get df to save\n",
    "df = combined_df.copy()\n",
    "df = df[df['value'] < 1000]\n",
    "df['log_value'] = df['value'].apply(np.log10)\n",
    "\n",
    "# Save data for regression task\n",
    "df.to_csv(f'{cur_dir}/data/regression.csv')\n",
    "df.to_json(f'{cur_dir}/data/regression.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac603b9-c943-4a8b-8cbe-a87dd7d0a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the number of entries per journal\n",
    "print('Number of entries for journal:')\n",
    "for journal in journals:\n",
    "    print(f'\\t{journal}: {len(df[df[\"journal\"] == journal])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6f9571-f3e7-44f1-8061-bcbd4ef44d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d1bad5-8772-48a6-bfdb-86111d0d5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_df = df[df.duplicated(['compound_name', 'smiles'])].sort_values(by='compound_name')\n",
    "duplicates_df.to_csv('duplicates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b7d87-e375-48cb-b91b-97dd58c0f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\tdoi\n",
    "1\t10.1016/s0960-894x(98)00653-2\n",
    "2\t10.1016/j.bmc.2020.115349\n",
    "3\t10.1021/jm400288z\n",
    "4\t10.1016/j.bmcl.2012.03.070\n",
    "5\t10.1021/jm021012t\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
