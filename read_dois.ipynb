{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3c1096-7a98-4d43-b7ee-37b000dd267e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99b80014-2a9f-4f1c-a1c6-132c9f61b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import math\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import lmdeploy\n",
    "from lmdeploy import GenerationConfig\n",
    "\n",
    "# Local imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47109d26-b56a-404e-8846-2d18267eaaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 8\n",
      "Device 0: Tesla V100-PCIE-32GB\n",
      "Device 1: Tesla V100-PCIE-32GB\n",
      "Device 2: Tesla V100-PCIE-32GB\n",
      "Device 3: Tesla V100-PCIE-32GB\n",
      "Device 4: Tesla V100-PCIE-32GB\n",
      "Device 5: Tesla V100-PCIE-32GB\n",
      "Device 6: Tesla V100-PCIE-32GB\n",
      "Device 7: Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "# Check available GPUs\n",
    "print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2938cd8b-7852-4423-867a-627a92c6eacf",
   "metadata": {},
   "source": [
    "# Llama-3.1-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba400323-1388-4318-9a6a-ac4c52eafe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce825d9696d44b9a1287271f2128eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "[TM][ERROR] CUDA runtime error: out of memory /lmdeploy/src/turbomind/utils/memory_utils.cu:32 \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Get model and move to GPU\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mlmdeploy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmeta-llama/Meta-Llama-3.1-8B-Instruct\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Set generation configuration\u001b[39;00m\n\u001b[1;32m     12\u001b[0m gen_config \u001b[38;5;241m=\u001b[39m GenerationConfig(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n",
      "File \u001b[0;32m/data/rbg/users/vincentf/wrickord/miniconda3/envs/ic50/lib/python3.11/site-packages/lmdeploy/api.py:77\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(model_path, backend_config, chat_template_config, log_level, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\n\u001b[1;32m     74\u001b[0m     backend_config) \u001b[38;5;129;01mis\u001b[39;00m PytorchEngineConfig \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mturbomind\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     75\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m engine\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipeline_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mchat_template_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchat_template_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/rbg/users/vincentf/wrickord/miniconda3/envs/ic50/lib/python3.11/site-packages/lmdeploy/serve/async_engine.py:154\u001b[0m, in \u001b[0;36mAsyncEngine.__init__\u001b[0;34m(self, model_path, model_name, backend, backend_config, chat_template_config, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# build backend engine\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mturbomind\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_turbomind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_pytorch(model_path\u001b[38;5;241m=\u001b[39mmodel_path,\n\u001b[1;32m    159\u001b[0m                         backend_config\u001b[38;5;241m=\u001b[39mbackend_config,\n\u001b[1;32m    160\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/data/rbg/users/vincentf/wrickord/miniconda3/envs/ic50/lib/python3.11/site-packages/lmdeploy/serve/async_engine.py:192\u001b[0m, in \u001b[0;36mAsyncEngine._build_turbomind\u001b[0;34m(self, model_path, backend_config, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Innter build method for turbomind backend.\"\"\"\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlmdeploy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m turbomind \u001b[38;5;28;01mas\u001b[39;00m tm\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m \u001b[43mtm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTurboMind\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mengine_config\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhf_tm_cfg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mconfig\n",
      "File \u001b[0;32m/data/rbg/users/vincentf/wrickord/miniconda3/envs/ic50/lib/python3.11/site-packages/lmdeploy/turbomind/turbomind.py:300\u001b[0m, in \u001b[0;36mTurboMind.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, model_name, chat_template_name, engine_config, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m model_source \u001b[38;5;241m=\u001b[39m get_model_source(pretrained_model_name_or_path)\n\u001b[1;32m    299\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_source: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_source\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m           \u001b[49m\u001b[43mchat_template_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchat_template_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m           \u001b[49m\u001b[43mengine_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmodel_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/rbg/users/vincentf/wrickord/miniconda3/envs/ic50/lib/python3.11/site-packages/lmdeploy/turbomind/turbomind.py:110\u001b[0m, in \u001b[0;36mTurboMind.__init__\u001b[0;34m(self, model_path, model_name, chat_template_name, engine_config, model_source, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m         model_path \u001b[38;5;241m=\u001b[39m get_model(model_path, _engine_config\u001b[38;5;241m.\u001b[39mdownload_dir,\n\u001b[1;32m    108\u001b[0m                                _engine_config\u001b[38;5;241m.\u001b[39mrevision)\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m Tokenizer(model_path)\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_comm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_hf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mengine_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_engine_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_count) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m     ranks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_id \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_count \u001b[38;5;241m+\u001b[39m device_id\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m device_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_count)\n\u001b[1;32m    118\u001b[0m     ]\n",
      "File \u001b[0;32m/data/rbg/users/vincentf/wrickord/miniconda3/envs/ic50/lib/python3.11/site-packages/lmdeploy/turbomind/turbomind.py:224\u001b[0m, in \u001b[0;36mTurboMind._from_hf\u001b[0;34m(self, model_source, model_path, engine_config)\u001b[0m\n\u001b[1;32m    217\u001b[0m model_comm \u001b[38;5;241m=\u001b[39m _tm\u001b[38;5;241m.\u001b[39mAbstractTransformerModel\u001b[38;5;241m.\u001b[39mcreate_llama_model(\n\u001b[1;32m    218\u001b[0m     model_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    219\u001b[0m     config\u001b[38;5;241m=\u001b[39myaml\u001b[38;5;241m.\u001b[39msafe_dump(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_dict),\n\u001b[1;32m    220\u001b[0m     tensor_para_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_count,\n\u001b[1;32m    221\u001b[0m     data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mweight_type)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# create empty weight\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_comm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# copy hf model weight to turbomind weight\u001b[39;00m\n\u001b[1;32m    227\u001b[0m tm_params \u001b[38;5;241m=\u001b[39m tm_model\u001b[38;5;241m.\u001b[39mtm_params\n",
      "File \u001b[0;32m/data/rbg/users/vincentf/wrickord/miniconda3/envs/ic50/lib/python3.11/site-packages/lmdeploy/turbomind/turbomind.py:150\u001b[0m, in \u001b[0;36mTurboMind._create_weight\u001b[0;34m(self, model_comm)\u001b[0m\n\u001b[1;32m    148\u001b[0m     futures\u001b[38;5;241m.\u001b[39mappend(executor\u001b[38;5;241m.\u001b[39msubmit(_create_weight_func, device_id))\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m futures:\n\u001b[0;32m--> 150\u001b[0m     \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/rbg/users/vincentf/wrickord/miniconda3/envs/ic50/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/data/rbg/users/vincentf/wrickord/miniconda3/envs/ic50/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data/rbg/users/vincentf/wrickord/miniconda3/envs/ic50/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/data/rbg/users/vincentf/wrickord/miniconda3/envs/ic50/lib/python3.11/site-packages/lmdeploy/turbomind/turbomind.py:143\u001b[0m, in \u001b[0;36mTurboMind._create_weight.<locals>._create_weight_func\u001b[0;34m(device_id)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_weight_func\u001b[39m(device_id):\n\u001b[1;32m    142\u001b[0m     rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_id \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_count \u001b[38;5;241m+\u001b[39m device_id\n\u001b[0;32m--> 143\u001b[0m     \u001b[43mmodel_comm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_shared_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [TM][ERROR] CUDA runtime error: out of memory /lmdeploy/src/turbomind/utils/memory_utils.cu:32 \n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "# Get model and move to GPU\n",
    "pipe = lmdeploy.pipeline(\n",
    "    'meta-llama/Meta-Llama-3.1-8B-Instruct'\n",
    ").to(DEVICE)\n",
    "\n",
    "# Set generation configuration\n",
    "gen_config = GenerationConfig(temperature=0, max_new_tokens=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf32456-0c85-4152-a16d-8dc388ec0849",
   "metadata": {},
   "source": [
    "# Check if Paper's Have Exact Value from Chembl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2060fe-c169-4614-a9d0-eafd6cc98518",
   "metadata": {},
   "outputs": [],
   "source": [
    "doi = '10.1016/j.bmcl.2010.08.086'\n",
    "txt_path = f'/data/rbg/users/vincentf/data_uncertainty/c340_txt/{doi.replace(\"/\", \"_\")}.txt'\n",
    "with open(txt_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Few-shot prompt with examples of input-output format\n",
    "response = pipe([\n",
    "    f'''    \n",
    "    You are tasked with summarizing data from the literature provided. The text will contain information about an IC50 assay \n",
    "    for a target: digestive enzyme Cytochrome P450 3A4 (CYP3A4), and we only care about CYP3A4 data, not other variants. \n",
    "\n",
    "    Your task is to summarize key experimental details like assay type, inhibitors, and conditions.\n",
    "    \n",
    "    The output should only include details present in the text; do not infer or add anything. \n",
    "\n",
    "    INPUT:\n",
    "    {text}\n",
    "    \n",
    "    OUTPUT:\n",
    "    '''\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d37ec80-98f3-4976-8564-08bf96026d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7cedf0-125e-4f52-a321-9af15072b2aa",
   "metadata": {},
   "source": [
    "# Chunk Data and See if It Contains Assay Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf9fbea-1510-4fb3-9288-323ef8526685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks no more than 1024 tokens\n",
    "token = pipe.tokenizer(\"text\")\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e251ed63-1094-4ae9-8776-ef7dc37e09ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
